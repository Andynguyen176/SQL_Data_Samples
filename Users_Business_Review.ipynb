{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Bay Area Dataheads\nAndy Nguyen, Cameron Cheung, Sergio Fernandez, Phillip Young \n#### Team Homework Assignment\n#### Professor Jensen || BUS-118S (SEC-01)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "source": "# Read Review Data\nRead the review data from round 11 of the Yelp Dataset Challenge. \nThe 5.2 million reviews in this data file include every review from the \nfollowing 11 cities, except those reviews that Yelp has filetered as not\nbeing recommended.\n* Las Vegas, NV\n* Phoenix, AZ\n* Madison, WI \n* Urbana-Champaign, IL\n* Cleveland, OH\n* Pittsburgh, PA\n* Charlotte, NC\n* Montreal (Canada)\n* Quebec (Canada)\n* Edinburgh (U.K.)\n* Karlsruhe, (Germany)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "number of reviews: 5261669\nroot\n |-- business_id: string (nullable = true)\n |-- cool: long (nullable = true)\n |-- date: string (nullable = true)\n |-- funny: long (nullable = true)\n |-- review_id: string (nullable = true)\n |-- stars: long (nullable = true)\n |-- text: string (nullable = true)\n |-- useful: long (nullable = true)\n |-- user_id: string (nullable = true)\n\n+--------------------+----+----------+-----+--------------------+-----+--------------------+------+--------------------+\n|         business_id|cool|      date|funny|           review_id|stars|                text|useful|             user_id|\n+--------------------+----+----------+-----+--------------------+-----+--------------------+------+--------------------+\n|0W4lkclzZThpx3V65...|   0|2016-05-28|    0|v0i_UHJMo_hPBq9bx...|    5|Love the staff, l...|     0|bv2nCi5Qv5vroFiqK...|\n|AEx2SYEUJmTxVVB18...|   0|2016-05-28|    0|vkVSCC7xljjrAI4UG...|    5|Super simple plac...|     0|bv2nCi5Qv5vroFiqK...|\n|VR6GpWIda3SfvPC-l...|   0|2016-05-28|    0|n6QzIUObkYshz4dz2...|    5|Small unassuming ...|     0|bv2nCi5Qv5vroFiqK...|\n|CKC0-MOWMqoeWf6s-...|   0|2016-05-28|    0|MV3CcKScW05u5LVfF...|    5|Lester's is locat...|     0|bv2nCi5Qv5vroFiqK...|\n|ACFtxLv8pGrrxMm6E...|   0|2016-05-28|    0|IXvOzsEMYtiJI0CAR...|    4|Love coming here....|     0|bv2nCi5Qv5vroFiqK...|\n+--------------------+----+----------+-----+--------------------+-----+--------------------+------+--------------------+\nonly showing top 5 rows\n\n"
                }
            ], 
            "source": "# Please read the documentation of PySpark to learn more about the possibilities to load data files.\n# PySpark documentation: https://spark.apache.org/docs/2.0.1/api/python/pyspark.sql.html#pyspark.sql.SparkSession\n# The SparkSession object is already initialized for you.\n# The following variable contains the path to your file on your IBM Cloud Object Storage.\n\npath_review = cos.url('review.json.bz2', 'spring2018andy023363be332e40639c4287c87e0af5e0')\ndf_reviews = spark.read.json(path_review)\nprint \"number of reviews:\", df_reviews.count()\ndf_reviews.printSchema()\ndf_reviews.show(5)"
        }, 
        {
            "source": "#Read User Data\nRead the user data from round 11 of the Yelp Dataset challenge. Includes users who wrote a review from any of the following (11) cities, except those reviews that Yelp has filtered as not being recommended.\n\n* Las Vegas, NV\n* Phoenix, AZ\n* Madison, WI\n* Urbana-Champaign, IL\n* Cleveland, OH\n* Pitssburgh, PA\n* Charlotte, NC\n* Montreal (Canada)\n* Quebec (Canada)\n* Karlsruhe, (Germany)", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "# USER'S\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Number of users: 1326101\nroot\n |-- average_stars: double (nullable = true)\n |-- compliment_cool: long (nullable = true)\n |-- compliment_cute: long (nullable = true)\n |-- compliment_funny: long (nullable = true)\n |-- compliment_hot: long (nullable = true)\n |-- compliment_list: long (nullable = true)\n |-- compliment_more: long (nullable = true)\n |-- compliment_note: long (nullable = true)\n |-- compliment_photos: long (nullable = true)\n |-- compliment_plain: long (nullable = true)\n |-- compliment_profile: long (nullable = true)\n |-- compliment_writer: long (nullable = true)\n |-- cool: long (nullable = true)\n |-- elite: array (nullable = true)\n |    |-- element: long (containsNull = true)\n |-- fans: long (nullable = true)\n |-- friends: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- funny: long (nullable = true)\n |-- name: string (nullable = true)\n |-- review_count: long (nullable = true)\n |-- useful: long (nullable = true)\n |-- user_id: string (nullable = true)\n |-- yelping_since: string (nullable = true)\n\n+-------------+---------------+---------------+----------------+--------------+---------------+---------------+---------------+-----------------+----------------+------------------+-----------------+----+-----+----+--------------------+-----+------+------------+------+--------------------+-------------+\n|average_stars|compliment_cool|compliment_cute|compliment_funny|compliment_hot|compliment_list|compliment_more|compliment_note|compliment_photos|compliment_plain|compliment_profile|compliment_writer|cool|elite|fans|             friends|funny|  name|review_count|useful|             user_id|yelping_since|\n+-------------+---------------+---------------+----------------+--------------+---------------+---------------+---------------+-----------------+----------------+------------------+-----------------+----+-----+----+--------------------+-----+------+------------+------+--------------------+-------------+\n|         4.67|              0|              0|               0|             0|              0|              0|              0|                0|               1|                 0|                0|   0|   []|   0|[cvVMmlU1ouS3I5fh...|    0|Johnny|           8|     0|oMy_rEb0UBEmMlu-z...|   2014-11-03|\n|          3.7|              0|              0|               0|             0|              0|              0|              0|                0|               0|                 0|                0|   0|   []|   0|[0njfJmB-7n84DlIg...|    0| Chris|          10|     0|JJ-aSuM4pCFPdkfoZ...|   2013-09-24|\n|          2.0|              0|              0|               0|             0|              0|              0|              0|                0|               0|                 0|                0|   0|   []|   0|                  []|    0| Tiffy|           1|     0|uUzsFQn_6cXDh6rPN...|   2017-03-02|\n|         4.67|              0|              0|               0|             0|              0|              0|              0|                0|               0|                 0|                0|   0|   []|   0|                  []|    0|  Mark|           6|     0|mBneaEEH5EMyxaVyq...|   2015-03-13|\n|         4.67|              0|              0|               0|             0|              0|              0|              0|                0|               0|                 0|                0|   0|   []|   0|                  []|    0|Evelyn|           3|     0|W5mJGs-dcDWRGEhAz...|   2016-09-08|\n+-------------+---------------+---------------+----------------+--------------+---------------+---------------+---------------+-----------------+----------------+------------------+-----------------+----+-----+----+--------------------+-----+------+------------+------+--------------------+-------------+\nonly showing top 5 rows\n\n"
                }
            ], 
            "source": "path_user = cos.url('user.json.bz2', 'spring2018andy023363be332e40639c4287c87e0af5e0') \ndf_users = spark.read.json(path_user) \nprint \"Number of users:\", df_users.count() \ndf_users.printSchema() \ndf_users.show(5)"
        }, 
        {
            "source": "# BUSINESS ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Number of users: 174567\nroot\n |-- address: string (nullable = true)\n |-- attributes: struct (nullable = true)\n |    |-- AcceptsInsurance: boolean (nullable = true)\n |    |-- AgesAllowed: string (nullable = true)\n |    |-- Alcohol: string (nullable = true)\n |    |-- Ambience: struct (nullable = true)\n |    |    |-- casual: boolean (nullable = true)\n |    |    |-- classy: boolean (nullable = true)\n |    |    |-- divey: boolean (nullable = true)\n |    |    |-- hipster: boolean (nullable = true)\n |    |    |-- intimate: boolean (nullable = true)\n |    |    |-- romantic: boolean (nullable = true)\n |    |    |-- touristy: boolean (nullable = true)\n |    |    |-- trendy: boolean (nullable = true)\n |    |    |-- upscale: boolean (nullable = true)\n |    |-- BYOB: boolean (nullable = true)\n |    |-- BYOBCorkage: string (nullable = true)\n |    |-- BestNights: struct (nullable = true)\n |    |    |-- friday: boolean (nullable = true)\n |    |    |-- monday: boolean (nullable = true)\n |    |    |-- saturday: boolean (nullable = true)\n |    |    |-- sunday: boolean (nullable = true)\n |    |    |-- thursday: boolean (nullable = true)\n |    |    |-- tuesday: boolean (nullable = true)\n |    |    |-- wednesday: boolean (nullable = true)\n |    |-- BikeParking: boolean (nullable = true)\n |    |-- BusinessAcceptsBitcoin: boolean (nullable = true)\n |    |-- BusinessAcceptsCreditCards: boolean (nullable = true)\n |    |-- BusinessParking: struct (nullable = true)\n |    |    |-- garage: boolean (nullable = true)\n |    |    |-- lot: boolean (nullable = true)\n |    |    |-- street: boolean (nullable = true)\n |    |    |-- valet: boolean (nullable = true)\n |    |    |-- validated: boolean (nullable = true)\n |    |-- ByAppointmentOnly: boolean (nullable = true)\n |    |-- Caters: boolean (nullable = true)\n |    |-- CoatCheck: boolean (nullable = true)\n |    |-- Corkage: boolean (nullable = true)\n |    |-- DietaryRestrictions: struct (nullable = true)\n |    |    |-- dairy-free: boolean (nullable = true)\n |    |    |-- gluten-free: boolean (nullable = true)\n |    |    |-- halal: boolean (nullable = true)\n |    |    |-- kosher: boolean (nullable = true)\n |    |    |-- soy-free: boolean (nullable = true)\n |    |    |-- vegan: boolean (nullable = true)\n |    |    |-- vegetarian: boolean (nullable = true)\n |    |-- DogsAllowed: boolean (nullable = true)\n |    |-- DriveThru: boolean (nullable = true)\n |    |-- GoodForDancing: boolean (nullable = true)\n |    |-- GoodForKids: boolean (nullable = true)\n |    |-- GoodForMeal: struct (nullable = true)\n |    |    |-- breakfast: boolean (nullable = true)\n |    |    |-- brunch: boolean (nullable = true)\n |    |    |-- dessert: boolean (nullable = true)\n |    |    |-- dinner: boolean (nullable = true)\n |    |    |-- latenight: boolean (nullable = true)\n |    |    |-- lunch: boolean (nullable = true)\n |    |-- HairSpecializesIn: struct (nullable = true)\n |    |    |-- africanamerican: boolean (nullable = true)\n |    |    |-- asian: boolean (nullable = true)\n |    |    |-- coloring: boolean (nullable = true)\n |    |    |-- curly: boolean (nullable = true)\n |    |    |-- extensions: boolean (nullable = true)\n |    |    |-- kids: boolean (nullable = true)\n |    |    |-- perms: boolean (nullable = true)\n |    |    |-- straightperms: boolean (nullable = true)\n |    |-- HappyHour: boolean (nullable = true)\n |    |-- HasTV: boolean (nullable = true)\n |    |-- Music: struct (nullable = true)\n |    |    |-- background_music: boolean (nullable = true)\n |    |    |-- dj: boolean (nullable = true)\n |    |    |-- jukebox: boolean (nullable = true)\n |    |    |-- karaoke: boolean (nullable = true)\n |    |    |-- live: boolean (nullable = true)\n |    |    |-- no_music: boolean (nullable = true)\n |    |    |-- video: boolean (nullable = true)\n |    |-- NoiseLevel: string (nullable = true)\n |    |-- Open24Hours: boolean (nullable = true)\n |    |-- OutdoorSeating: boolean (nullable = true)\n |    |-- RestaurantsAttire: string (nullable = true)\n |    |-- RestaurantsCounterService: boolean (nullable = true)\n |    |-- RestaurantsDelivery: boolean (nullable = true)\n |    |-- RestaurantsGoodForGroups: boolean (nullable = true)\n |    |-- RestaurantsPriceRange2: long (nullable = true)\n |    |-- RestaurantsReservations: boolean (nullable = true)\n |    |-- RestaurantsTableService: boolean (nullable = true)\n |    |-- RestaurantsTakeOut: boolean (nullable = true)\n |    |-- Smoking: string (nullable = true)\n |    |-- WheelchairAccessible: boolean (nullable = true)\n |    |-- WiFi: string (nullable = true)\n |-- business_id: string (nullable = true)\n |-- categories: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- city: string (nullable = true)\n |-- hours: struct (nullable = true)\n |    |-- Friday: string (nullable = true)\n |    |-- Monday: string (nullable = true)\n |    |-- Saturday: string (nullable = true)\n |    |-- Sunday: string (nullable = true)\n |    |-- Thursday: string (nullable = true)\n |    |-- Tuesday: string (nullable = true)\n |    |-- Wednesday: string (nullable = true)\n |-- is_open: long (nullable = true)\n |-- latitude: double (nullable = true)\n |-- longitude: double (nullable = true)\n |-- name: string (nullable = true)\n |-- neighborhood: string (nullable = true)\n |-- postal_code: string (nullable = true)\n |-- review_count: long (nullable = true)\n |-- stars: double (nullable = true)\n |-- state: string (nullable = true)\n\n+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+-------+----------+------------+--------------------+------------+-----------+------------+-----+-----+\n|             address|          attributes|         business_id|          categories|          city|               hours|is_open|  latitude|   longitude|                name|neighborhood|postal_code|review_count|stars|state|\n+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+-------+----------+------------+--------------------+------------+-----------+------------+-----+-----+\n|4855 E Warner Rd,...|[true,null,null,n...|FYWN1wneV18bWNgQj...|[Dentists, Genera...|     Ahwatukee|[7:30-17:00,7:30-...|      1|33.3306902|-111.9785992|    Dental by Design|            |      85044|          22|  4.0|   AZ|\n|  3101 Washington Rd|[null,null,null,n...|He-G7vWjzVUysIKrf...|[Hair Stylists, H...|      McMurray|[9:00-16:00,9:00-...|      1|40.2916853| -80.1048999| Stephen Szabo Salon|            |      15317|          11|  3.0|   PA|\n|6025 N 27th Ave, ...|[null,null,null,n...|KQPW8lFf1y5BT2Mxi...|[Departments of M...|       Phoenix|[null,null,null,n...|      1|33.5249025|-112.1153098|Western Motor Veh...|            |      85017|          18|  1.5|   AZ|\n|5000 Arizona Mill...|[null,null,null,n...|8DShNS-LuFqpEWIp0...|[Sporting Goods, ...|         Tempe|[10:00-21:00,10:0...|      0|33.3831468|-111.9647254|    Sports Authority|            |      85282|           9|  3.0|   AZ|\n|        581 Howe Ave|[null,null,full_b...|PfOCPjBrlQAnz__NX...|[American (New), ...|Cuyahoga Falls|[11:00-1:00,11:00...|      1|41.1195346| -81.4756898|Brick House Taver...|            |      44221|         116|  3.5|   OH|\n+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+-------+----------+------------+--------------------+------------+-----------+------------+-----+-----+\nonly showing top 5 rows\n\n"
                }
            ], 
            "source": "path_business = cos.url('business.json.bz2', 'spring2018andy023363be332e40639c4287c87e0af5e0') \ndf_business = spark.read.json(path_business) \nprint \"Number of users:\", df_business.count() \ndf_business.printSchema() \ndf_business.show(5)"
        }, 
        {
            "source": "# Transforming the Review and User Data\nUsing Spark select function again to do a transformation where we filter out those columns that are not needed.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Filtered Reviews\n+--------------------+--------------------+--------------------+-----+-------------+\n|           review_id|             user_id|         business_id|stars|review_length|\n+--------------------+--------------------+--------------------+-----+-------------+\n|v0i_UHJMo_hPBq9bx...|bv2nCi5Qv5vroFiqK...|0W4lkclzZThpx3V65...|    5|          289|\n|vkVSCC7xljjrAI4UG...|bv2nCi5Qv5vroFiqK...|AEx2SYEUJmTxVVB18...|    5|          213|\n|n6QzIUObkYshz4dz2...|bv2nCi5Qv5vroFiqK...|VR6GpWIda3SfvPC-l...|    5|          502|\n|MV3CcKScW05u5LVfF...|bv2nCi5Qv5vroFiqK...|CKC0-MOWMqoeWf6s-...|    5|          373|\n|IXvOzsEMYtiJI0CAR...|bv2nCi5Qv5vroFiqK...|ACFtxLv8pGrrxMm6E...|    4|          523|\n+--------------------+--------------------+--------------------+-----+-------------+\nonly showing top 5 rows\n\n"
                }
            ], 
            "source": "from pyspark.sql import functions \ndf_filtered_reviews = df_reviews.select(df_reviews.review_id, df_reviews.user_id,\n                                       df_reviews.business_id, df_reviews.stars,\n                                       functions.length(df_reviews.text).alias('review_length'))\nprint \"Filtered Reviews\"\ndf_filtered_reviews.show(5)"
        }, 
        {
            "source": "This function filters out the columns that are unnecessary. \nThe table is similar to pulling a users information or a license ID. The yelp results consist of name, review count, average ratings, member since, \nand if he or she is an elite member. The conditional statement in the formula helps filter users if they are elite level or not. If their records show\ngreater than 0 it will show as \"true.\"", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Filtered users: \n+--------------------+------+------------+-------------+-------------+--------+\n|             user_id|  name|review_count|average_stars|yelping_since|is_elite|\n+--------------------+------+------------+-------------+-------------+--------+\n|oMy_rEb0UBEmMlu-z...|Johnny|           8|         4.67|   2014-11-03|   false|\n|JJ-aSuM4pCFPdkfoZ...| Chris|          10|          3.7|   2013-09-24|   false|\n|uUzsFQn_6cXDh6rPN...| Tiffy|           1|          2.0|   2017-03-02|   false|\n|mBneaEEH5EMyxaVyq...|  Mark|           6|         4.67|   2015-03-13|   false|\n|W5mJGs-dcDWRGEhAz...|Evelyn|           3|         4.67|   2016-09-08|   false|\n+--------------------+------+------------+-------------+-------------+--------+\nonly showing top 5 rows\n\n"
                }
            ], 
            "source": "#Filtered Yelp Users\ndf_filtered_users = df_users.select(df_users.user_id, df_users.name, df_users.review_count, \n                                   df_users.average_stars, df_users.yelping_since, \n                                   (functions.size(df_users.elite)>0).alias('is_elite'))\nprint \"Filtered users: \"\ndf_filtered_users.show(5)"
        }, 
        {
            "source": "# Averages and Counts by User in the Dataset\nRegrouping review records based on the user_id field, so that the field is automatically included in the DataFrame generated in this information. \nThe primary focus of the function is to find the averages of the review ratings, length, and count which will display the top 5 rows. \nThe second chart is just a rename of the table columns compared to the first.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Average Review Ratings, Lengths, and Count: \n+--------------------+----------------+------------------+------------------+\n|             user_id|count(review_id)|        avg(stars)|avg(review_length)|\n+--------------------+----------------+------------------+------------------+\n|Cx5V6BvXk7Gm1_B5l...|               1|               5.0|             511.0|\n|cQ5ItbXkfadNScisz...|               2|               5.0|             574.0|\n|GF2eVXOpG16w6xY59...|               1|               5.0|             235.0|\n|jcA8OaFX75vih2Xwf...|               3|3.6666666666666665| 458.3333333333333|\n|kjAZyaTn9Wqa2u1u-...|               1|               1.0|            1621.0|\n+--------------------+----------------+------------------+------------------+\nonly showing top 5 rows\n\n+--------------------+-----------------+-----------------+--------------------+\n|             user_id|dataset_avg_stars|avg_review_length|dataset_review_count|\n+--------------------+-----------------+-----------------+--------------------+\n|wrxM9KTQAqF0-W_Hz...|             3.75|           202.75|                   4|\n|X2S5Cq8MEsLn63-6C...|4.571428571428571|            173.0|                   7|\n|CNHpjq5Vfs3c16C9-...|              1.0|            528.0|                   1|\n|zcp42G-kVhNOJIZSX...|              2.0|            839.0|                   2|\n|RMdcyXgulzkMRvFbN...|              1.0|            663.0|                   1|\n+--------------------+-----------------+-----------------+--------------------+\nonly showing top 5 rows\n\n"
                }
            ], 
            "source": "print \"Average Review Ratings, Lengths, and Count: \"\ndf_agg_rev = df_filtered_reviews.groupBy('user_id')\\\n.agg({'stars':'avg','review_length':'avg','review_id': 'count'})\n\ndf_agg_rev.show(5)\n\ndf_agg_reviews = df_agg_rev.select('user_id', 'avg(stars)', 'avg(review_length)', 'count(review_id)')\\\n.toDF('user_id', 'dataset_avg_stars','avg_review_length','dataset_review_count')\n\ndf_agg_reviews.show(5)"
        }, 
        {
            "source": "# Combined Users x Review\nBoth users and reviews were stated in the codes above so for this purpose they will both be combined. \nThis will create a bigger table displaying more of the users information. \nAn SQL function is used for this to select the relevant information. (inner join x select)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "User Reviews:\n+--------------------+-------------+------------+-------------+-------------+--------+-----------------+-----------------+--------------------+\n|             user_id|         name|review_count|average_stars|yelping_since|is_elite|dataset_avg_stars|avg_review_length|dataset_review_count|\n+--------------------+-------------+------------+-------------+-------------+--------+-----------------+-----------------+--------------------+\n|--CJT4d-S8UhwqHe0...|        Scott|           3|          2.0|   2015-08-18|   false|              1.0|           1956.0|                   1|\n|-0Ji0nOyFe-4yo8BK...|         cubs|          57|         3.28|   2009-05-15|   false|              4.0|             64.0|                   1|\n|-0XPr1ilUAfp-yIXZ...|Fairmount Jil|           3|         1.25|   2007-12-26|   false|              2.0|           1849.0|                   1|\n|-1KKYzibGPyUX-Mwk...|       Nickie|         163|          4.0|   2009-08-07|    true|              4.0|            510.0|                   1|\n|-1zQA2f_syMAdA04P...|         Zach|           4|          3.0|   2014-06-22|   false|              3.0|            289.5|                   4|\n+--------------------+-------------+------------+-------------+-------------+--------+-----------------+-----------------+--------------------+\nonly showing top 5 rows\n\n"
                }
            ], 
            "source": "\ndf_users_reviews = df_filtered_users.join(df_agg_reviews, 'user_id', 'left')\\\n.select (df_filtered_users.user_id, 'name', 'review_count', 'average_stars',\n         'yelping_since', 'is_elite', 'dataset_avg_stars', \n         'avg_review_length', 'dataset_review_count')\n\nprint \"User Reviews:\"\n\ndf_users_reviews.show(5)"
        }, 
        {
            "source": "# Profiling the Dataset\nCalculate the percentage of each user's reviews that are in the dataset. This will automatically displayed the first 20 rows.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+--------------------+-------------+------------+-------------+-------------+--------+------------------+-----------------+--------------------+--------------------+\n|             user_id|         name|review_count|average_stars|yelping_since|is_elite| dataset_avg_stars|avg_review_length|dataset_review_count|  dataset_percentage|\n+--------------------+-------------+------------+-------------+-------------+--------+------------------+-----------------+--------------------+--------------------+\n|--CJT4d-S8UhwqHe0...|        Scott|           3|          2.0|   2015-08-18|   false|               1.0|           1956.0|                   1|  0.3333333333333333|\n|-0Ji0nOyFe-4yo8BK...|         cubs|          57|         3.28|   2009-05-15|   false|               4.0|             64.0|                   1|0.017543859649122806|\n|-0XPr1ilUAfp-yIXZ...|Fairmount Jil|           3|         1.25|   2007-12-26|   false|               2.0|           1849.0|                   1|  0.3333333333333333|\n|-1KKYzibGPyUX-Mwk...|       Nickie|         163|          4.0|   2009-08-07|    true|               4.0|            510.0|                   1|0.006134969325153374|\n|-1zQA2f_syMAdA04P...|         Zach|           4|          3.0|   2014-06-22|   false|               3.0|            289.5|                   4|                 1.0|\n|-2Pb5d2WBPtbyGT_b...|        mindy|           5|          3.2|   2009-04-29|   false|               5.0|            285.0|                   1|                 0.2|\n|-2mPrKWc9UYdvTrOZ...|         Gary|           1|          5.0|   2016-08-21|   false|               5.0|            499.0|                   1|                 1.0|\n|-3bsS2i9xqjNnIA1f...|          Kim|          15|         2.47|   2012-04-10|   false|               2.5|           1520.5|                   2| 0.13333333333333333|\n|-3i9bhfvrM3F1wsC9...|        Linda|         604|         4.06|   2005-08-07|    true|3.4285714285714284|            574.5|                  14|0.023178807947019868|\n|-4Anvj46CWf57KWI9...|       Cookie|           2|          3.5|   2016-08-17|   false|               3.5|            459.0|                   2|                 1.0|\n+--------------------+-------------+------------+-------------+-------------+--------+------------------+-----------------+--------------------+--------------------+\nonly showing top 10 rows\n\n"
                }
            ], 
            "source": "\ndf_dataset_percentage = df_users_reviews.select('user_id', 'name',\\\n                                               'review_count', 'average_stars', 'yelping_since', 'is_elite', \\\n                                               'dataset_avg_stars', 'avg_review_length', 'dataset_review_count',\\\n                                               (df_users_reviews.dataset_review_count / df_users_reviews.review_count).alias('dataset_percentage'))\n\ndf_dataset_percentage.show(10)"
        }, 
        {
            "source": "# Percentage of User's Reviews (Count)\nFor this code, it will display a count based off the percentage of the user's reviews in the dataset that exceed 100%. \nThe actual count turned out to be 51.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+--------+\n|count(1)|\n+--------+\n|      51|\n+--------+\n\nroot\n |-- user_id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- review_count: long (nullable = true)\n |-- average_stars: double (nullable = true)\n |-- yelping_since: string (nullable = true)\n |-- is_elite: boolean (nullable = false)\n |-- dataset_avg_stars: double (nullable = true)\n |-- avg_review_length: double (nullable = true)\n |-- dataset_review_count: long (nullable = true)\n |-- dataset_percentage: double (nullable = true)\n\n"
                }
            ], 
            "source": "\ndf_dataset_percentage.filter(df_dataset_percentage.dataset_percentage > 1.0).agg({'*':'count'}).show() \ndf_dataset_percentage.printSchema()"
        }, 
        {
            "source": "# Sort the data percentage\nSame process as the last code but there will be no count instead we will be sorting the data and display the first 100 result. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+--------------------+---------+------------+-------------+-------------+--------+------------------+------------------+--------------------+------------------+\n|             user_id|     name|review_count|average_stars|yelping_since|is_elite| dataset_avg_stars| avg_review_length|dataset_review_count|dataset_percentage|\n+--------------------+---------+------------+-------------+-------------+--------+------------------+------------------+--------------------+------------------+\n|Gd9goxOHld8UOWYqs...|    Lanny|           1|         2.62|   2011-04-09|   false|3.5833333333333335| 428.3333333333333|                  12|              12.0|\n|SnEgF9J2NRptXjskX...|   Regina|           5|          3.1|   2015-02-03|   false|3.2972972972972974| 363.8378378378378|                  37|               7.4|\n|Pfkoyhdup4UeFOslJ...|     Seth|           1|         4.86|   2015-02-21|   false|               5.0|             407.0|                   4|               4.0|\n|GXnPGaeM334u_e_JC...|        Y|           2|         3.85|   2009-07-26|   false| 4.428571428571429| 920.2857142857143|                   7|               3.5|\n|1duCTLdmqXHqd5WGe...|       Lo|           1|         3.47|   2009-03-25|    true|               5.0|175.66666666666666|                   3|               3.0|\n|RGKIVa5bGSqX5vMnp...|  Andrews|           9|         4.14|   2014-09-01|   false|              4.05|            549.15|                  20|2.2222222222222223|\n|bgmffI7VNYbia4yOZ...|    Sarah|           2|          3.0|   2012-10-25|   false|               3.0|            942.25|                   4|               2.0|\n|M_k8osDw9Wn6XV96R...|Christian|           1|          1.5|   2017-04-07|   false|               1.5|             466.5|                   2|               2.0|\n|XXvfUheazyf-RrLB_...|Pon-yeeah|           1|         4.75|   2013-01-10|   false|               5.0|             364.5|                   2|               2.0|\n|BqvJOhn0QKRSj7Cxd...|      Tom|           1|          1.0|   2016-05-26|   false|               1.0|             610.0|                   2|               2.0|\n|N3_acAlXyiaOl8MSu...|     Rose|           1|          3.0|   2017-02-05|   false|               3.0|             146.5|                   2|               2.0|\n|_apv24N3nLwIdPrHx...|    Udell|           1|          1.0|   2017-01-22|   false|               1.0|             802.5|                   2|               2.0|\n|Qg42D4N2l-tUBJ1eX...|    Jenny|           3|         4.17|   2014-06-22|   false|               4.2|             180.8|                   5|1.6666666666666667|\n|oP_guLe__P5BKsTMc...|    Conor|           2|          3.0|   2016-11-10|   false|3.6666666666666665| 733.3333333333334|                   3|               1.5|\n|8GpM-QUlb0V9DP56X...|     Jess|           2|         3.67|   2016-05-01|   false|3.6666666666666665|             458.0|                   3|               1.5|\n|-CgbL7Rygee52C3yl...|      Kim|           2|          2.5|   2017-01-06|   false|               3.0|            1406.0|                   3|               1.5|\n|MqjTaPHdrotau9Pfm...|     Matt|           2|          5.0|   2013-05-16|   false|               5.0|            1196.0|                   3|               1.5|\n|XJO8ZygvC_isYnDWk...|     Eric|           2|          4.0|   2012-02-04|   false|3.6666666666666665|             343.0|                   3|               1.5|\n|S0hQ2Xbfz1R9c6a69...|     Alex|           2|         4.25|   2016-10-23|   false|               4.0|             441.0|                   3|               1.5|\n|ZegUGw7AUB0fjJDEy...|   Kelsey|           2|         3.67|   2016-07-16|   false|3.6666666666666665| 622.3333333333334|                   3|               1.5|\n|WTWe_JqDZlnYAJ8_B...|     Lina|           2|          4.0|   2017-01-07|   false|               4.0| 535.3333333333334|                   3|               1.5|\n|upRAv2okAqxzUfnjE...|    Chris|           2|          3.2|   2017-05-02|   false|3.3333333333333335| 411.3333333333333|                   3|               1.5|\n|UnP006Mbi-AqSTn23...|      Avi|           2|          4.0|   2013-07-18|   false|               5.0| 325.3333333333333|                   3|               1.5|\n|QPFyfh2vkdWs2aNrF...|      Mag|           2|          5.0|   2017-01-17|   false|               5.0|             178.0|                   3|               1.5|\n|smLJbNzjlVx2wsH6g...|     Lexi|           3|          3.0|   2014-10-21|   false|               3.0|             471.0|                   4|1.3333333333333333|\n|6cba0fI0-Hog52YFL...|Christina|           3|          3.6|   2015-09-08|   false|               4.0|            713.25|                   4|1.3333333333333333|\n|87v53p49Kh_m7caV8...|   Aniket|           3|          5.0|   2014-08-08|   false|               5.0|             168.5|                   4|1.3333333333333333|\n|QM-dtt5FAFUBi2mt_...|  Melissa|           3|          5.0|   2014-03-02|   false|               5.0|            419.75|                   4|1.3333333333333333|\n|7RL3qW5IqoD4Mu3X1...|     Bill|           3|          2.0|   2016-08-17|   false|               2.0|            432.75|                   4|1.3333333333333333|\n|AZ1WEuHI2C-cRaXS-...|  Cecilia|           3|          3.9|   2014-07-31|   false|              3.75|             888.0|                   4|1.3333333333333333|\n|sLbjJ2OTQOLSnMJLA...|    Allix|           3|          2.8|   2016-11-14|   false|              3.25|             631.5|                   4|1.3333333333333333|\n|sOL4vqXDrGGm0fPyV...| Samantha|           4|          4.2|   2014-05-02|   false|               4.2|             670.6|                   5|              1.25|\n|3Hv7dnRcwC4IBEvUy...|        S|           4|          3.4|   2012-04-17|   false|               3.4|             145.4|                   5|              1.25|\n|vf3u305Cp4wwreUx8...|        J|           4|          4.2|   2014-10-25|   false|               4.2|             252.0|                   5|              1.25|\n|jDoR1VKY9mnWur0YV...|    Maika|           4|         4.25|   2013-10-21|   false|               4.8|             252.8|                   5|              1.25|\n|C_LxqoDy2nwwTZX7X...|   Ashley|           5|          3.0|   2014-05-09|   false|               3.0| 306.1666666666667|                   6|               1.2|\n|CqO8EBO8K7wV6cyAv...|   Maggie|           5|         2.79|   2016-09-26|   false|2.1666666666666665| 365.6666666666667|                   6|               1.2|\n|qNeb0IsEKPR6K9Igt...|        N|           6|         3.86|   2014-08-27|   false| 3.857142857142857|212.14285714285714|                   7|1.1666666666666667|\n|2y9cPgLYd4Okx6Zk1...|     Ivan|           6|          2.4|   2012-07-31|   false|2.5714285714285716|             769.0|                   7|1.1666666666666667|\n|z0MLuGcYk8olNQ7TC...|    Laura|           6|         3.44|   2012-12-17|   false|3.5714285714285716| 735.8571428571429|                   7|1.1666666666666667|\n|xCMMiUeEunMpXnh8b...| Samantha|           6|         4.63|   2015-03-20|   false| 4.571428571428571| 400.2857142857143|                   7|1.1666666666666667|\n|_wYJcDJ8YWCqFdU3C...| Cristina|           7|         3.15|   2014-11-17|   false|               3.5|            334.75|                   8|1.1428571428571428|\n|elf4PucDzGfsKk4ps...|    Sarah|           7|          4.0|   2016-07-18|   false|               4.5|           438.625|                   8|1.1428571428571428|\n|hbQobvcC07W0zQA_9...|     Dave|           8|         3.67|   2013-03-01|   false|               4.0|349.22222222222223|                   9|             1.125|\n|sO0EQAiJVB5FUOvCO...|     Rose|           9|         3.92|   2013-11-24|   false|               3.9|             300.9|                  10|1.1111111111111112|\n|fL5CQ4s4ANUvwsU0h...|    Scott|          10|         3.44|   2016-05-26|   false|3.3636363636363638| 400.8181818181818|                  11|               1.1|\n|ddPFBOsvFjaOVRj8s...|   Brandi|          11|         3.24|   2014-06-26|   false| 4.416666666666667| 553.4166666666666|                  12|1.0909090909090908|\n|hOPE0YPENSZhsC-nl...|  Abigail|          15|         3.25|   2015-07-23|   false|              3.25|             600.0|                  16|1.0666666666666667|\n|0LQZIzeAsJgLdrRp4...|     Rose|          23|         2.05|   2014-07-02|   false|2.0833333333333335|1054.4583333333333|                  24|1.0434782608695652|\n|v8DTz8SQRMlFdWrpC...|    Sarah|          31|         3.67|   2007-04-14|    true|           3.40625|         839.53125|                  32| 1.032258064516129|\n|EdDmKiz6V89g6Dws9...|    Harry|          73|         3.79|   2016-01-27|    true| 3.689189189189189|473.35135135135135|                  74|1.0136986301369864|\n+--------------------+---------+------------+-------------+-------------+--------+------------------+------------------+--------------------+------------------+\n\n"
                }
            ], 
            "source": "df_dataset_percentage.filter(df_dataset_percentage.dataset_percentage > 1.0)\\\n.sort('dataset_percentage', ascending=False).show(100)\n"
        }, 
        {
            "source": "# How many businesses are there in each of the nine North American Cities?", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "This will pull data from the \"BUSINESS\" table which we will use to extract the 9 metropolitan areas in North America. Using the CASE WHEN function allows the query to pull only specific metropolitan areas and then a count function will be added to sum businesses for each city. Also, Charlotte is considered adding both the states South Carolina (SC) and North Carolina (NC). The primary focus is to discover which North American cities has the most business. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Number of Businesses in the 9 North American Cities: \n+--------------------+-----+\n|Metropolitan_Areas  |count|\n+--------------------+-----+\n|Montreal, Canada    |264  |\n|Urbana-Champaign, IL|384  |\n|Madison, WI         |3213 |\n|Cleveland, OH       |3322 |\n|Pittsburgh, PA      |6355 |\n|Quebec, Canada      |7906 |\n|Charlotte, NC       |9232 |\n|Phoenix, AZ         |17213|\n|Las Vegas, NV       |26775|\n+--------------------+-----+\nonly showing top 9 rows\n\n"
                }
            ], 
            "source": "df_business.createOrReplaceTempView(\"business\")\n\nprint (\"Number of Businesses in the 9 North American Cities: \")\n\ndf_north_america = spark.sql(\"\"\"\nSELECT \n    CASE\n      WHEN City = \"Las Vegas\" THEN \"Las Vegas, NV\"\n      WHEN City = \"Phoenix\" THEN \"Phoenix, AZ\"\n      WHEN City = \"Madison\" THEN \"Madison, WI\"\n      WHEN City = \"Urbana\" THEN \"Urbana-Champaign, IL\"\n      WHEN City = \"Cleveland\" THEN \"Cleveland, OH\"\n      WHEN City = \"Pittsburgh\" THEN \"Pittsburgh, PA\"\n      WHEN City = \"Charlotte\" OR State = \"SC\" THEN \"Charlotte, NC\"\n      WHEN City = \"Montreal\" THEN \"Montreal, Canada\"\n      WHEN State = \"QC\" THEN \"Quebec, Canada\"\n    END AS Metropolitan_Areas\nFROM business\n\"\"\")\n\ndf_north_america.groupBy('Metropolitan_Areas').count().orderBy('count').show(9, truncate = False)\n\ndf_north_america.createOrReplaceTempView(\"numero\")"
        }, 
        {
            "source": "# How many continuing locals are there in the dataset?", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "We want to discover how many local users have written at least 10 reviews and have over 50% of their reviews. The query previously grabs the established data table \"dataset_percentage\" calculated earlier. The results returned 88,301 continuing local users in the dataset with the requirements. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Locals with at least 10 reviews and contain 50%: \n+------+\n|Locals|\n+------+\n|88301 |\n+------+\n\n"
                }
            ], 
            "source": "df_dataset_percentage.createOrReplaceTempView(\"dataset_percentage\")\n\nprint \"Locals with at least 10 reviews and contain 50%: \"\n\ndf_locals = spark.sql(\"\"\"\nSELECT COUNT(user_id) AS Locals\nFROM dataset_percentage\nWHERE review_count >= 10 AND dataset_percentage > 0.5\n\"\"\")\n\ndf_locals.show(truncate = False)"
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "root\n |-- Locals: long (nullable = false)\n\n"
                }
            ], 
            "source": "df_locals.createOrReplaceTempView(\"locals\")\ndf_locals.printSchema()"
        }, 
        {
            "source": "# How many reviews are there in each of the nine cities?", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In the code below, we create a dataframe that shows us the 9 states and the review count for each.  However, there is one catch to convert states with the value 'SC' to be converted to 'NC'.  'SC' values that are converted to 'NC' will still be their own row as shown below.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+------+-------------+\n|States|Total_Reviews|\n+------+-------------+\n|    NV|      1824387|\n|    AZ|      1627693|\n|    ON|       634263|\n|    NC|       307426|\n|    OH|       243677|\n|    PA|       229804|\n|    QC|       146379|\n|    WI|       109737|\n|    IL|        36378|\n|    NC|        10857|\n+------+-------------+\n\n"
                }
            ], 
            "source": "df_total_reviews = spark.sql(\"\"\"\nSELECT IF(state = 'SC', 'NC', state) as States, SUM(review_count) as Total_Reviews\nFROM business \nWHERE (state = 'NV' \nOR state ='AZ' \nOR state ='WI'\nOR state ='IL'\nOR state ='OH'\nOR state ='PA'\nOR state ='NC' \nOR state ='QC'\nOR state ='ON'\nOR state = 'SC')\nGROUP BY state\nORDER BY total_reviews DESC\n\"\"\")\n\ndf_total_reviews.show()\n\n"
        }, 
        {
            "source": "The below code creates a dataframe that we will use to sum the two seperate 'NC' rows together ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "root\n |-- States: string (nullable = true)\n |-- Total_Reviews: long (nullable = true)\n\n"
                }
            ], 
            "source": "df_total_reviews.createOrReplaceTempView(\"combined\")\ndf_total_reviews.printSchema()"
        }, 
        {
            "source": "The below code is a SQL query ran on the \"combined\" dataframe that sums up the two NC rows to make one row.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 18, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+------+-------+\n|States|Reviews|\n+------+-------+\n|NV    |1824387|\n|AZ    |1627693|\n|ON    |634263 |\n|NC    |318283 |\n|OH    |243677 |\n|PA    |229804 |\n|QC    |146379 |\n|WI    |109737 |\n|IL    |36378  |\n+------+-------+\n\n"
                }
            ], 
            "source": "df_combined = spark.sql(\"\"\"\nSELECT states as States, sum(Total_Reviews) AS Reviews\nFROM combined\nGROUP BY states\nORDER BY sum(Total_Reviews) DESC\n\"\"\")\ndf_combined.show(truncate = False)"
        }, 
        {
            "execution_count": 19, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df_business.createOrReplaceTempView(\"business\")\ndf_reviews.createOrReplaceTempView(\"reviews\")\ndf_users.createOrReplaceTempView(\"users\")\ndf_dataset_percentage.createOrReplaceTempView(\"dataset\")\ndf_combined.createOrReplaceTempView(\"state_reviews\")"
        }, 
        {
            "source": "# Which percentage of each metro area's reviews were writen by users who are continuing locals?\nThe result should be a DataFrame (DF) where you show with the following 4 columns: \n    * Metro area (this can be the state code)\n    * Number of reviews (total)\n    * Number of reviews in that metro areas by continuing locals\n    * Percentage of reviews in that metro areas by continuing locals\nThe result should be sorted based on the perecentage in that last column. You can use DataFrames (DF), Temporary Views (TV), or a combination of both in answering the question. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "This SQL dataset will be represented by \"df_dataset_reviews\" which will be joined with the \"reviews\" table specifically on their user_id and continuing locals who have review counts of at least 10 and their dataset_percentage is greater than 50%. This will match up their user id's for the next queries.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 20, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+------------------+------------+----------------------+\n|Dataset_Percentage|Review_Count|business_id           |\n+------------------+------------+----------------------+\n|0.5945945945945946|22          |WXR0ND0KqbArMZDvFMA-bw|\n|0.5945945945945946|22          |3qlqzQrwh8hjBltlgFgsJQ|\n|0.5945945945945946|22          |nn4ZkIZTCd7jJhxs-P9tHA|\n|0.5945945945945946|22          |RezqChEv5DPJC85d20R85A|\n|0.5945945945945946|22          |_e3rChyednoh47n2cjGv2w|\n|0.5945945945945946|22          |Mypk1XBD6PQ77zLXyMiKhg|\n|0.5945945945945946|22          |F-QY0xyNi9z1p0wjZvnk3g|\n|0.5945945945945946|22          |qrK73viBBJY_hx3bgRQw7w|\n|0.5945945945945946|22          |9O-L6F0cMfNmE5i07pN_xQ|\n|0.5945945945945946|22          |T-KniGykrZ46ZC9plOTspw|\n|0.5945945945945946|22          |DaVTuhzi6EgWStb2eAjNjA|\n|0.5945945945945946|22          |LIxNfkk9vgPikLh1W-5f8w|\n|0.5945945945945946|22          |wHq1efQVz17338k_aUOX3w|\n|0.5945945945945946|22          |C3VnuPP_flttZPokgU2mLw|\n|0.5945945945945946|22          |twoxa0_9sn6ZN4j40kDsuA|\n|0.5945945945945946|22          |VuYF1vGKLjEFaQfL4Ypwqg|\n|0.5945945945945946|22          |ZxA3HG1kxD-0ZzKuealTFA|\n|0.5945945945945946|22          |6t98--hqg8suYkm_37re8w|\n|0.5945945945945946|22          |po-05-AGCVxEme-SbNUIKw|\n|0.5945945945945946|22          |3awTUGMdUVrwEBkFFOxn9Q|\n+------------------+------------+----------------------+\nonly showing top 20 rows\n\n"
                }
            ], 
            "source": "\ndf_dataset_reviews = spark.sql(\"\"\"\nSELECT \n    D.dataset_percentage as Dataset_Percentage, \n    D.dataset_review_count as Review_Count, \n    R.business_id  \nFROM dataset as D\nINNER JOIN reviews as R\nON D.user_id = R.user_id\nWHERE review_count >= 10 AND dataset_percentage > 0.5\n\"\"\")\n\ndf_dataset_reviews.show(20, truncate = False)"
        }, 
        {
            "execution_count": 21, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "root\n |-- Dataset_Percentage: double (nullable = true)\n |-- Review_Count: long (nullable = true)\n |-- business_id: string (nullable = true)\n\n"
                }
            ], 
            "source": "#Creates a temporary view of the previous query and set to \"dataset1\"\ndf_dataset_reviews.createOrReplaceTempView(\"dataset1\")\ndf_dataset_reviews.printSchema()"
        }, 
        {
            "source": "The second query, we will inner join this with the \"business\" database now specifically to match up their business_id. Our end goal is to make sure that each user id is matched up correctly and that are from the metro areas. In this purpose, we were able to pull state in this dataset which will be used for the next query. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 22, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+------------------+------------+----------------------+-----+\n|dataset_percentage|review_count|business_id           |state|\n+------------------+------------+----------------------+-----+\n|0.5945945945945946|22          |WXR0ND0KqbArMZDvFMA-bw|AZ   |\n|0.5945945945945946|22          |3qlqzQrwh8hjBltlgFgsJQ|AZ   |\n|0.5945945945945946|22          |nn4ZkIZTCd7jJhxs-P9tHA|AZ   |\n|0.5945945945945946|22          |RezqChEv5DPJC85d20R85A|AZ   |\n|0.5945945945945946|22          |_e3rChyednoh47n2cjGv2w|AZ   |\n|0.5945945945945946|22          |Mypk1XBD6PQ77zLXyMiKhg|AZ   |\n|0.5945945945945946|22          |F-QY0xyNi9z1p0wjZvnk3g|AZ   |\n|0.5945945945945946|22          |qrK73viBBJY_hx3bgRQw7w|AZ   |\n|0.5945945945945946|22          |9O-L6F0cMfNmE5i07pN_xQ|AZ   |\n|0.5945945945945946|22          |T-KniGykrZ46ZC9plOTspw|AZ   |\n|0.5945945945945946|22          |DaVTuhzi6EgWStb2eAjNjA|AZ   |\n|0.5945945945945946|22          |LIxNfkk9vgPikLh1W-5f8w|AZ   |\n|0.5945945945945946|22          |wHq1efQVz17338k_aUOX3w|AZ   |\n|0.5945945945945946|22          |C3VnuPP_flttZPokgU2mLw|AZ   |\n|0.5945945945945946|22          |twoxa0_9sn6ZN4j40kDsuA|AZ   |\n|0.5945945945945946|22          |VuYF1vGKLjEFaQfL4Ypwqg|AZ   |\n|0.5945945945945946|22          |ZxA3HG1kxD-0ZzKuealTFA|AZ   |\n|0.5945945945945946|22          |6t98--hqg8suYkm_37re8w|AZ   |\n|0.5945945945945946|22          |po-05-AGCVxEme-SbNUIKw|AZ   |\n|0.5945945945945946|22          |3awTUGMdUVrwEBkFFOxn9Q|AZ   |\n+------------------+------------+----------------------+-----+\nonly showing top 20 rows\n\n"
                }
            ], 
            "source": "df_dataset_business = spark.sql(\"\"\"\nSELECT d.dataset_percentage,\n       d.review_count, \n       b.business_id, \n       b.state\nFROM dataset1 as d\nINNER JOIN business as b \nON d.business_id = b.business_id\n\"\"\")\n\ndf_dataset_business.show(truncate = False)"
        }, 
        {
            "execution_count": 23, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#Creates a temporary view \ndf_dataset_business.createOrReplaceTempView(\"dataset_business\")"
        }, 
        {
            "source": "Finally, we can put all the pieces together before we get to the data cleaning phase. Previously, we found the total reviews of the 9 metro areas above and now we want to inner join on states. We set the previous query to \"dataset_business\" to join on \"state_reviews\" so now it will focus on specifically the 9 areas.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 24, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+------------------+------------+----------------------+-----+-------------+\n|dataset_percentage|review_count|business_id           |state|total_reviews|\n+------------------+------------+----------------------+-----+-------------+\n|0.5945945945945946|22          |WXR0ND0KqbArMZDvFMA-bw|AZ   |1627693      |\n|0.5945945945945946|22          |3qlqzQrwh8hjBltlgFgsJQ|AZ   |1627693      |\n|0.5945945945945946|22          |nn4ZkIZTCd7jJhxs-P9tHA|AZ   |1627693      |\n|0.5945945945945946|22          |RezqChEv5DPJC85d20R85A|AZ   |1627693      |\n|0.5945945945945946|22          |_e3rChyednoh47n2cjGv2w|AZ   |1627693      |\n|0.5945945945945946|22          |Mypk1XBD6PQ77zLXyMiKhg|AZ   |1627693      |\n|0.5945945945945946|22          |F-QY0xyNi9z1p0wjZvnk3g|AZ   |1627693      |\n|0.5945945945945946|22          |qrK73viBBJY_hx3bgRQw7w|AZ   |1627693      |\n|0.5945945945945946|22          |9O-L6F0cMfNmE5i07pN_xQ|AZ   |1627693      |\n|0.5945945945945946|22          |T-KniGykrZ46ZC9plOTspw|AZ   |1627693      |\n|0.5945945945945946|22          |DaVTuhzi6EgWStb2eAjNjA|AZ   |1627693      |\n|0.5945945945945946|22          |LIxNfkk9vgPikLh1W-5f8w|AZ   |1627693      |\n|0.5945945945945946|22          |wHq1efQVz17338k_aUOX3w|AZ   |1627693      |\n|0.5945945945945946|22          |C3VnuPP_flttZPokgU2mLw|AZ   |1627693      |\n|0.5945945945945946|22          |twoxa0_9sn6ZN4j40kDsuA|AZ   |1627693      |\n|0.5945945945945946|22          |VuYF1vGKLjEFaQfL4Ypwqg|AZ   |1627693      |\n|0.5945945945945946|22          |ZxA3HG1kxD-0ZzKuealTFA|AZ   |1627693      |\n|0.5945945945945946|22          |6t98--hqg8suYkm_37re8w|AZ   |1627693      |\n|0.5945945945945946|22          |po-05-AGCVxEme-SbNUIKw|AZ   |1627693      |\n|0.5945945945945946|22          |3awTUGMdUVrwEBkFFOxn9Q|AZ   |1627693      |\n+------------------+------------+----------------------+-----+-------------+\nonly showing top 20 rows\n\n"
                }
            ], 
            "source": "df_all_together = spark.sql(\"\"\"\nSELECT d.dataset_percentage, \n       d.review_count,\n       d.business_id, \n       d.state, \n       s.Reviews as total_reviews\nFROM dataset_business as d\nINNER JOIN state_reviews as s\non d.state = s.states\n\"\"\")\n\ndf_all_together.show(20, truncate = False)"
        }, 
        {
            "execution_count": 25, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "root\n |-- dataset_percentage: double (nullable = true)\n |-- review_count: long (nullable = true)\n |-- business_id: string (nullable = true)\n |-- state: string (nullable = true)\n |-- total_reviews: long (nullable = true)\n\n"
                }
            ], 
            "source": "df_all_together.createOrReplaceTempView(\"all_together\")\ndf_all_together.printSchema()"
        }, 
        {
            "source": "The cleaning phase now. We pull the first \"total_reviews\" from the query above and count the states up which we will label local_reviews. This will allow us to find the total percetnage of reviews in the metro areas for continuing locals. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 26, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+-----+-----------+-------------+\n|state|all_reviews|local_reviews|\n+-----+-----------+-------------+\n|   AZ|    1627693|       748244|\n|   QC|     146379|        57390|\n|   NV|    1824387|       609923|\n|   WI|     109737|        36330|\n|   NC|     318283|       114314|\n|   IL|      36378|         7837|\n|   OH|     243677|        91599|\n|   PA|     229804|        82982|\n|   ON|     634263|       374431|\n+-----+-----------+-------------+\n\n"
                }
            ], 
            "source": "\ndf_final = spark.sql(\"\"\"\nSELECT state, \n       first(total_reviews) as all_reviews, \n       count(state) as local_reviews\nFROM all_together\nGROUP BY state\n\"\"\")\n\ndf_final.show()"
        }, 
        {
            "execution_count": 27, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "root\n |-- state: string (nullable = true)\n |-- all_reviews: long (nullable = true)\n |-- local_reviews: long (nullable = false)\n\n"
                }
            ], 
            "source": "df_final.createOrReplaceTempView(\"final\")\ndf_final.printSchema()"
        }, 
        {
            "source": "A dataframe is used here named \"df_final_2\" which we want to select all the columns from the previous table. We divide local_reviews to all_reviews and multiply it by 100 to find the percentage. We will label that as local_percentage_of_total. Based off the results, it looks like Ontario has the most continuing locals that still post reviews at 59% with locals in Arizona coming in second at 45%. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 31, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+-----+-----------+-------------+-------------------------+\n|state|all_reviews|local_reviews|local_percentage_of_total|\n+-----+-----------+-------------+-------------------------+\n|   AZ|    1627693|       748244|       45.969602375878004|\n|   QC|     146379|        57390|        39.20644354723014|\n|   NV|    1824387|       609923|        33.43166773277819|\n|   WI|     109737|        36330|        33.10642718499685|\n|   NC|     318283|       114314|       35.915835907038705|\n|   IL|      36378|         7837|        21.54324042003409|\n|   OH|     243677|        91599|         37.5903347464061|\n|   PA|     229804|        82982|        36.10990235156916|\n|   ON|     634263|       374431|        59.03402847083938|\n+-----+-----------+-------------+-------------------------+\n\n"
                }
            ], 
            "source": "#LAST FINAL PIECE FINALLY\ndf_final_2 = df_final.select('state', 'all_reviews','local_reviews',\n((df_final.local_reviews / df_final.all_reviews) * 100).alias('local_percentage_of_total')).show()"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.14", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}